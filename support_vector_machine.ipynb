{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Using GridSearchCV in order to fine tune the model's hyperparameters for the iris dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM classifier\n",
    "svc = SVC()\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50), (100, 100)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'learning_rate': ['constant', 'adaptive', 'invscaling', 'learning_rate_init', 'power_t', 'beta_1'],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'max_iter': [2000, 5000, 10000]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV with the classifier, parameter grid, and cross-validation\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=3, scoring='accuracy', verbose=1)\n",
    "\n",
    "# Perform the grid search on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters for the iris dataset:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of the model for the best hyperparameters:\", accuracy)\n",
    "print(\"Classification Report of the model for the best hyperparameters:\\n\", classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using GridSearchCV in order to fine tune the model's hyperparameters for the breast cancer dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load the Breast Cancer dataset\n",
    "breast_cancer = load_breast_cancer()\n",
    "X = breast_cancer.data\n",
    "y = breast_cancer.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM classifier\n",
    "svc = SVC()\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50), (100, 100)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'learning_rate': ['constant', 'adaptive', 'invscaling', 'learning_rate_init', 'power_t'],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'max_iter': [2000, 5000, 10000]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV with the classifier, parameter grid, and cross-validation\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "\n",
    "# Perform the grid search on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters for the breast cancer dataset:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of the model for the best hyperparameters:\", accuracy)\n",
    "print(\"Classification Report of the model for the best hyperparameters:\\n\", classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using GridSearchCV in order to fine tune the model's hyperparameters for the ionosphere dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Ionosphere dataset\n",
    "ionosphere = pd.read_csv('https://raw.githubusercontent.com/hargurjeet/MachineLearning/Ionosphere/ionosphere_data.csv')\n",
    "ionosphere.rename(columns={'column_ai': 'target'}, inplace=True)\n",
    "\n",
    "X = ionosphere.drop(['target'], axis=1)\n",
    "y = ionosphere.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an SVM classifier\n",
    "svc = SVC()\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50), (100, 100)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'learning_rate': ['constant', 'adaptive', 'invscaling', 'learning_rate_init', 'power_t'],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'max_iter': [2000, 5000, 10000]\n",
    "}\n",
    "\n",
    "# Create GridSearchCV with the classifier, parameter grid, and cross-validation\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "\n",
    "# Perform the grid search on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters for the ionosphere dataset:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy of the model for the best hyperparameters:\", accuracy)\n",
    "print(\"Classification Report of the model for the best hyperparameters:\\n\", classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "iris = load_iris()\n",
    "i = iris.feature_names\n",
    "iris_Y = iris.target\n",
    "iris = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "b = breast_cancer.feature_names\n",
    "breast_cancer_Y = breast_cancer.target\n",
    "breast_cancer = pd.DataFrame(data=breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "\n",
    "ionosphere = pd.read_csv('https://raw.githubusercontent.com/hargurjeet/MachineLearning/Ionosphere/ionosphere_data.csv')\n",
    "ionosphere.rename(columns={'column_ai': 'target'}, inplace=True)\n",
    "# print(ionosphere)\n",
    "\n",
    "iris_X = iris[i]\n",
    "breast_cancer_X = breast_cancer[b]\n",
    "ionosphere_X = ionosphere.drop(['target'], axis=1)\n",
    "ionosphere_Y = ionosphere.target\n",
    "\n",
    "\n",
    "def svm_accuracy_vs_split_plot(start_split=10, end_split=70, dataset='iris', iterations=500):\n",
    "    accuracies = []\n",
    "    split_values = []\n",
    "\n",
    "    if dataset == 'iris':\n",
    "        X = iris_X\n",
    "        y = iris_Y\n",
    "        for i in range(start_split, end_split + 1, 10):\n",
    "            split_values.append(i / 100)\n",
    "            acc = 0\n",
    "            for j in range(0, iterations):\n",
    "                train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=None, test_size=i / 100)\n",
    "                model = SVC()\n",
    "                model.fit(train_X, train_y)\n",
    "                pred_y = model.predict(test_X)\n",
    "                acc += accuracy_score(test_y, pred_y)\n",
    "            acc /= iterations\n",
    "            accuracies.append(acc)\n",
    "    if dataset == 'breast_cancer':\n",
    "        X = breast_cancer_X\n",
    "        y = breast_cancer_Y\n",
    "        for i in range(start_split, end_split + 1, 10):\n",
    "            split_values.append(i / 100)\n",
    "            acc = 0\n",
    "            for j in range(0, iterations):\n",
    "                train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=None, test_size=i / 100)\n",
    "                model = SVC()\n",
    "                model.fit(train_X, train_y)\n",
    "                pred_y = model.predict(test_X)\n",
    "                acc += accuracy_score(test_y, pred_y)\n",
    "            acc /= iterations\n",
    "            accuracies.append(acc)\n",
    "    elif dataset == 'ionosphere':\n",
    "        X = ionosphere_X\n",
    "        y = ionosphere_Y\n",
    "        X = breast_cancer_X\n",
    "        y = breast_cancer_Y\n",
    "        for i in range(start_split, end_split + 1, 10):\n",
    "            split_values.append(i / 100)\n",
    "            acc = 0\n",
    "            for j in range(0, iterations):\n",
    "                train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=None, test_size=i / 100)\n",
    "                model = SVC()\n",
    "                model.fit(train_X, train_y)\n",
    "                pred_y = model.predict(test_X)\n",
    "                acc += accuracy_score(test_y, pred_y)\n",
    "            acc /= iterations\n",
    "            accuracies.append(acc)\n",
    "\n",
    "    print(accuracies)\n",
    "    print(split_values)\n",
    "\n",
    "    data = pd.DataFrame(list(zip(accuracies, split_values)), columns=['Accuracies', 'Train-Test Splits'])\n",
    "    sns.lineplot(data=data, y='Accuracies', x='Train-Test Splits').set_title(\n",
    "        dataset + \": Accuracy vs Train-Test Split plot with fine tuned MLP model, over \" + str(\n",
    "            iterations) + \" iterations on each split\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svm_accuracy_vs_split_plot(dataset='iris')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
